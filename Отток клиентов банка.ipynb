{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Импортируем-библиотеки-которые,-скорее-всего-нам,-понадобятся\" data-toc-modified-id=\"Импортируем-библиотеки-которые,-скорее-всего-нам,-понадобятся-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Импортируем библиотеки которые, скорее всего нам, понадобятся</a></span></li><li><span><a href=\"#Подготовка-данных\" data-toc-modified-id=\"Подготовка-данных-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Подготовка данных</a></span></li><li><span><a href=\"#Выводы:\" data-toc-modified-id=\"Выводы:-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы:</a></span></li><li><span><a href=\"#Исследование-задачи\" data-toc-modified-id=\"Исследование-задачи-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Исследование задачи</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Начнем-с-модели-логистической-регрессии.\" data-toc-modified-id=\"Начнем-с-модели-логистической-регрессии.-4.0.1\"><span class=\"toc-item-num\">4.0.1&nbsp;&nbsp;</span>Начнем с модели логистической регрессии.</a></span></li><li><span><a href=\"#Дерево-решений\" data-toc-modified-id=\"Дерево-решений-4.0.2\"><span class=\"toc-item-num\">4.0.2&nbsp;&nbsp;</span>Дерево решений</a></span></li><li><span><a href=\"#Случайный-лес\" data-toc-modified-id=\"Случайный-лес-4.0.3\"><span class=\"toc-item-num\">4.0.3&nbsp;&nbsp;</span>Случайный лес</a></span></li></ul></li></ul></li><li><span><a href=\"#Выводы:\" data-toc-modified-id=\"Выводы:-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Выводы:</a></span></li><li><span><a href=\"#Борьба-с-дисбалансом\" data-toc-modified-id=\"Борьба-с-дисбалансом-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Борьба с дисбалансом</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Начнем-со-взвешивния-классов.-Так-как-аргумент-class_weight-можно-использовать-со-всеми-используемыми-нами-моделями,-то-будем-использовать-его-и-посмотрим-как-поменяются-результаты-при-class_weight='balanced.\" data-toc-modified-id=\"Начнем-со-взвешивния-классов.-Так-как-аргумент-class_weight-можно-использовать-со-всеми-используемыми-нами-моделями,-то-будем-использовать-его-и-посмотрим-как-поменяются-результаты-при-class_weight='balanced.-6.0.1\"><span class=\"toc-item-num\">6.0.1&nbsp;&nbsp;</span>Начнем со взвешивния классов. Так как аргумент class_weight можно использовать со всеми используемыми нами моделями, то будем использовать его и посмотрим как поменяются результаты при class_weight='balanced.</a></span></li><li><span><a href=\"#Теперь-попробуем-изменение-порога\" data-toc-modified-id=\"Теперь-попробуем-изменение-порога-6.0.2\"><span class=\"toc-item-num\">6.0.2&nbsp;&nbsp;</span>Теперь попробуем изменение порога</a></span></li></ul></li></ul></li><li><span><a href=\"#Выводы:\" data-toc-modified-id=\"Выводы:-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Выводы:</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Модель-случайного-леса,-при-значении-гиперпараметра-n_estimators=85,-указании-атрибута-class_weight='balanced'-и-изменении-порога,-равным-0.28-показала-наилучший-результат.\" data-toc-modified-id=\"Модель-случайного-леса,-при-значении-гиперпараметра-n_estimators=85,-указании-атрибута-class_weight='balanced'-и-изменении-порога,-равным-0.28-показала-наилучший-результат.-7.0.1\"><span class=\"toc-item-num\">7.0.1&nbsp;&nbsp;</span>Модель случайного леса, при значении гиперпараметра n_estimators=85, указании атрибута class_weight='balanced' и изменении порога, равным 0.28 показала наилучший результат.</a></span></li></ul></li></ul></li><li><span><a href=\"#Тестирование-модели\" data-toc-modified-id=\"Тестирование-модели-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Тестирование модели</a></span><ul class=\"toc-item\"><li><span><a href=\"#Проверка-на-адекватность\" data-toc-modified-id=\"Проверка-на-адекватность-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>Проверка на адекватность</a></span><ul class=\"toc-item\"><li><span><a href=\"#Показатели-у-лучшего-(при--strategy='uniform')-из-фиктивных-классификаторов-гораздо-ниже,-чем-у-нашей-модели.\" data-toc-modified-id=\"Показатели-у-лучшего-(при--strategy='uniform')-из-фиктивных-классификаторов-гораздо-ниже,-чем-у-нашей-модели.-8.1.1\"><span class=\"toc-item-num\">8.1.1&nbsp;&nbsp;</span>Показатели у лучшего (при  <code>strategy='uniform'</code>) из фиктивных классификаторов гораздо ниже, чем у нашей модели.</a></span></li></ul></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-8.2\"><span class=\"toc-item-num\">8.2&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#Чек-лист-готовности-проекта\" data-toc-modified-id=\"Чек-лист-готовности-проекта-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Чек-лист готовности проекта</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отток клиентов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.\n",
    "\n",
    "Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Вам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. \n",
    "\n",
    "Постройте модель с предельно большим значением *F1*-меры. Чтобы сдать проект успешно, нужно довести метрику до 0.59. Проверьте *F1*-меру на тестовой выборке самостоятельно.\n",
    "\n",
    "Дополнительно измеряйте *AUC-ROC*, сравнивайте её значение с *F1*-мерой.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импортируем библиотеки которые, скорее всего нам, понадобятся"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим наш датасет и пропишем два пути - для выполнения на сервере и локально. И сразу просмотрим информацию по нему."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv('D:\\\\DS\\\\Обучение с учителем\\\\churn.csv')\n",
    "except:\n",
    "    df = pd.read_csv('/datasets/Churn.csv')\n",
    "    \n",
    "print(df.info())\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашем ДФ присутствуют следующие столбцы:\n",
    "* RowNumber — индекс строки в данных. Количественный тип данных\n",
    "* CustomerId — уникальный идентификатор клиента. Количественный тип данных\n",
    "* Surname — фамилия. Качественный тип данных\n",
    "* CreditScore — кредитный рейтинг. Количественный тип данных \n",
    "* Geography — страна проживания. Качественный тип данных\n",
    "* Gender — пол. Качественный тип данных\n",
    "* Age — возраст. Количественный тип данных\n",
    "* Tenure — сколько лет человек является клиентом банка. Количественный тип данных\n",
    "* Balance — баланс на счёте. Количественный тип данных\n",
    "* NumOfProducts — количество продуктов банка, используемых клиентом. Количественный тип данных\n",
    "* HasCrCard — наличие кредитной карты. Количественный (дискретный) тип данных.\n",
    "* IsActiveMember — активность клиента. Количественный (дискретный) тип данных.\n",
    "* EstimatedSalary — предполагаемая зарплата. Количественный тип данных.\n",
    "* Exited — факт ухода клиента. Количественный (дискретный) тип данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим на дубликаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Количесвто дубликатов:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим из нашего датафрейма столбцы, которые, не содержат никакой, в нашем случае, полезной информации для анализа, при этом лишняя информация может плохо повлиять на адеватность нашей модели. Такие столбцы: RowNumber, CustomerID, Surname."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns={'RowNumber','CustomerId', 'Surname'} , axis=1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь изучим данные в нашем ДФ с помощью describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что есть пропущенные значения. Они находятся только в столбце с количеством лет которые клиент обслуживается в банке, а именно tenure. Можно пофиксить это тремя способами:\n",
    "*  заменить пропущенные значение на 0\n",
    "*  заполнить медианным значением\n",
    "*  и радикальное - удалить строки с прпусками.\n",
    "\n",
    "Удалять строки я не буду, так как это потеря почти 10% данных. Попробую заменить на 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tenure']=df['Tenure'].fillna(0).astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"box-shadow: 0px 0px 10px 5px white;\"><span style=\"font-weight: bold;\"></span> вот тут думал еще заполнить средним значением, но без какой либо веской причины решил менять на 0.   если бы решил заполнять средним, то ориентировался бы на возраст и пол клиентов. то есть что то вроде этого\n",
    "    <br></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def refill_tenure(row):\n",
    "    #age = row.loc['Age']\n",
    "    #gender = row.loc['Gender']\n",
    "    #tenure = row.loc['Tenure']\n",
    "    #if math.isnan(tenure):\n",
    "        #tenure = df.loc[(df['Age']==age) & (df['Gender']==gender)]['Tenure'].median()\n",
    "    #return tenure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"box-shadow: 0px 0px 10px 5px white;\"><span style=\"font-weight: bold;\"></span> ну и применял бы эту функцию к df['tenure'], если не доведу меру до 0.59 при заполнении 0, то попробую заполнить  средним значением.\n",
    "    <br></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Tenure']=df['Tenure'].fillna(0).astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверирим остались ли пропуски."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['Tenure'].isna())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "не осталось"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как мы решаем задачу классификации (уйдет клиент или не уйдет), а в нашем ДФ почти все столбцы, кроме Gender и Geography, количественные - преобразуем категориальные переменные в количественные.\n",
    "И что бы не попасть в \"дамми -ловушку\" укажем drop_first=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohe = pd.get_dummies(df, drop_first=True)\n",
    "df_ohe.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим наш ДФ на обучающую, валидационную и тестовую выборки в соотношении 3:1:1. И Сразу проверим как прошло разделение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df_ohe['Exited']\n",
    "features = df_ohe.drop('Exited', axis=1)\n",
    "features_train, features_2, target_train, target_2 = train_test_split(\n",
    "    features, target, test_size=0.4, random_state=12345)\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(\n",
    "    features_2, target_2, test_size=0.5, random_state=12345)\n",
    "\n",
    "print(features_train.shape[0])\n",
    "print(features_valid.shape[0])\n",
    "print(features_test.shape[0])\n",
    "\n",
    "print(target_train.shape[0])\n",
    "print(target_valid.shape[0])\n",
    "target_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как у нас в разных столбцах разный разброс в значениях данных, то, что бы не было прирогативы одного из признаков, используем стандартизацию с помощью StandardScaler(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью transform() преобразыем наши выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(features_train)\n",
    "features_train = scaler.transform(features_train)\n",
    "features_valid = scaler.transform(features_valid)\n",
    "features_test = scaler.transform(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы:\n",
    "* Изучили данные в полученном дата фрейме\n",
    "* удалили ненужные, для анализа, столбцы, а именно  - 'RowNumber', 'CustomerId',  'Surname'\n",
    "* заполнили пропуски в 'Tenure' \n",
    "* перевели столбцы 'Gender' и 'Geography' из категориальных переменных в количественные \n",
    "* обозначили обучающую, валидационную и тестовую выборки\n",
    "* стандартизировали данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследование задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того что бы понять какую метрику использовать для определения точности модели  - проверим как соотносятся значения целевого признака др с другом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим соотношение примерно 4 к 1, а значит нет баланса классов и метрика accuracy нам не подойдет. Значит используем F1 меру и так же будем сразу подсчитывать AUC-ROC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Начнем с модели логистической регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model.fit(features_train, target_train)\n",
    "predictions = model.predict(features_valid)\n",
    "valid_f1score = f1_score(target_valid, predictions)\n",
    "\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "\n",
    "print(\"F1-мера:\", valid_f1score)\n",
    "print('AUC-ROC:', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Дерево решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью цикла определим лучшее значение гиперпараметра - max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['max_depth', 'f1_score', 'auc_roc']\n",
    "data = []\n",
    "\n",
    "for depth in range(1, 16):\n",
    "    model = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    model.fit(features_train,target_train) \n",
    "    predictions = model.predict(features_valid)\n",
    "    valid_f1score = f1_score(target_valid, predictions)\n",
    "    probabilities_valid = model.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "    auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "    data.append([depth, valid_f1score, auc_roc])\n",
    "frame = pd.DataFrame(data = data, columns=col)\n",
    "print(frame[frame['f1_score']==frame['f1_score'].max()]) \n",
    "print(frame[frame['auc_roc']==frame['auc_roc'].max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что максимальное  значение F1-меры  0.578 при значении max_depth=9. А максимальное значение AUC-ROC 0.822 при значении max_depth=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Случайный лес"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью цикла определим лучшее значение гиперпараметра - n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['n_estimators', 'f1_score', 'auc_roc']\n",
    "data = []\n",
    "\n",
    "for est in range(1, 100):\n",
    "    model = RandomForestClassifier(random_state=12345, n_estimators=est) \n",
    "    model.fit(features_train,target_train) \n",
    "    predictions = model.predict(features_valid)\n",
    "    f1 = f1_score(target_valid, predictions)\n",
    "    probabilities_valid = model.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "    auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "    data.append([est, f1, auc_roc])\n",
    "frame = pd.DataFrame(data = data, columns=col)\n",
    "print(frame[frame['f1_score']==frame['f1_score'].max()]) \n",
    "print(frame[frame['auc_roc']==frame['auc_roc'].max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что максимальное  значение F1-меры  0.594 при значении n_estimators = 51. А максимальное значение AUC-ROC 0.842 при значении n_estimators = 97"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы:\n",
    "* выяснили, что данные не сбалансированны соотношением примерно 4 к 1.\n",
    "* изучили модели для решения задачи классификации, посчитали F1 и AUC-ROC меняя и подбирая оптимальные значения гиперпараметров.\n",
    "* логистическая регрессия: F1-меры: 0.333, AUC-ROC: 0.758\n",
    "* дерево решений: F1-меры: 0.578 при max_depth = 9 , AUC-ROC: 0.822 при max_depth = 5\n",
    "* случайный  лес: F1-меры: 0.594 при  n_estimators = 51 , AUC-ROC: 0.842 n_estimators = 97"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Борьба с дисбалансом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Начнем со взвешивния классов. Так как аргумент class_weight можно использовать со всеми используемыми нами моделями, то будем использовать его и посмотрим как поменяются результаты при class_weight='balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=12345, solver='liblinear', class_weight='balanced')\n",
    "model.fit(features_train, target_train)\n",
    "predictions = model.predict(features_valid)\n",
    "valid_f1score = f1_score(target_valid, predictions)\n",
    "print(\"F1-мера:\", valid_f1score)\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print('AUC-ROC:', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1-мера увеличилилась и стала 0.488 (было 0.333),  AUC-ROC также увеличилась и стало 0.763 (было 0.758)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дерево решений (как и прошлый раз применим цикл)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['max_depth', 'f1_score', 'auc_roc']\n",
    "data = []\n",
    "\n",
    "for depth in range(1, 16):\n",
    "    model = DecisionTreeClassifier(random_state=12345, max_depth=depth, class_weight='balanced')\n",
    "    model.fit(features_train,target_train) \n",
    "    predictions = model.predict(features_valid)\n",
    "    valid_f1score = f1_score(target_valid, predictions)\n",
    "    probabilities_valid = model.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "    auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "    data.append([depth, valid_f1score, auc_roc])\n",
    "frame = pd.DataFrame(data = data, columns=col)\n",
    "print(frame[frame['f1_score']==frame['f1_score'].max()]) \n",
    "print(frame[frame['auc_roc']==frame['auc_roc'].max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось, что в данном случае и для F1 и для AUC-ROC оптимальным оказалось  max_depth = 5, при этом оба показателя выросли F1 0.596 (было 0.578), а AUC-ROC 0.831 (было 0.822)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Случайный лес (как и прошлый раз применим цикл)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['n_estimators', 'f1_score', 'auc_roc']\n",
    "data = []\n",
    "\n",
    "for est in range(1, 100):\n",
    "    model = RandomForestClassifier(random_state=12345, n_estimators=est, class_weight='balanced') \n",
    "    model.fit(features_train,target_train) \n",
    "    predictions = model.predict(features_valid)\n",
    "    f1 = f1_score(target_valid, predictions)\n",
    "    probabilities_valid = model.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "    auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "    data.append([est, f1, auc_roc])\n",
    "frame = pd.DataFrame(data = data, columns=col)\n",
    "print(frame[frame['f1_score']==frame['f1_score'].max()]) \n",
    "print(frame[frame['auc_roc']==frame['auc_roc'].max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 уменьшилась и стала 0.565 при n_estimators = 85 (было 0.594 при n_estimators = 51)  AUC-ROC тоже уменьшилась и стала 0.838 при n_estimators = 98 (было 0.842 при n_estimators = 97)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Теперь попробуем изменение порога"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическа регрессия (попробуем циклом подобрать оптимальный порог в промежутке от 0 до 1 с шагом 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model.fit(features_train, target_train)\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "col = ['порог', 'f1_score', 'auc_roc']\n",
    "data = []\n",
    "for threshold in np.arange(0, 1, 0.02):\n",
    "    predicted_valid = probabilities_one_valid > threshold\n",
    "    valid_f1score = f1_score(target_valid, predicted_valid )\n",
    "    auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "    data.append([threshold, valid_f1score, auc_roc])\n",
    "frame = pd.DataFrame(data = data, columns=col)\n",
    "print(frame[frame['f1_score']==frame['f1_score'].max()]) \n",
    "print(frame[frame['auc_roc']==frame['auc_roc'].max()].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Максимальная F1 = 0.499 при пороге 0.26. AUC-ROC = 0.758"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дерево решений (так как мы выяснили, что оптимальный  max_depth = 5, то и поставим это значение и применим цикл для поиска оптимального порога)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  DecisionTreeClassifier(random_state=12345, max_depth=5, class_weight='balanced')\n",
    "model.fit(features_train, target_train)\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "col = ['порог', 'f1_score', 'auc_roc']\n",
    "data = []\n",
    "for threshold in np.arange(0, 1, 0.02):\n",
    "    predicted_valid = probabilities_one_valid > threshold\n",
    "    valid_f1score = f1_score(target_valid, predicted_valid )\n",
    "    auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "    data.append([threshold, valid_f1score, auc_roc])\n",
    "frame = pd.DataFrame(data = data, columns=col)\n",
    "print(frame[frame['f1_score']==frame['f1_score'].max()]) \n",
    "print(frame[frame['auc_roc']==frame['auc_roc'].max()].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось, что максимальное значение F1 получилось при нескольких значениях порога и равно 0.608. Так как порог 0.58 ближайший к порогу по умолчанию(0.5) то оствим его. AUC-ROC = 0.831."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Случайный лес (так как мы выяснили, что оптимальный  n_estimators = 85, то и поставим это значение и применим цикл для поиска оптимального порога)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=12345, n_estimators=85, class_weight='balanced') \n",
    "model.fit(features_train, target_train)\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "col = ['порог', 'f1_score', 'auc_roc']\n",
    "data = []\n",
    "for threshold in np.arange(0, 1, 0.02):\n",
    "    predicted_valid = probabilities_one_valid > threshold\n",
    "    valid_f1score = f1_score(target_valid, predicted_valid )\n",
    "    auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "    data.append([threshold, valid_f1score, auc_roc])\n",
    "frame = pd.DataFrame(data = data, columns=col)\n",
    "print(frame[frame['f1_score']==frame['f1_score'].max()]) \n",
    "print(frame[frame['auc_roc']==frame['auc_roc'].max()].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Максимальная F1 = 0.619 при пороге 0.28. AUC-ROC = 0.837"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы:\n",
    "Применили два метода для борьбы с дисбалансом классов: взвешивание и изменение порога.\n",
    "Взвешивание дало следующие результаты:\n",
    "* логистическая регрессия: F1-мера = 0.488, AUC-ROC = 0.763\n",
    "* решающее дерево: F1-мера = 0.596 AUC-ROC = 0.831, при  max_depth = 5\n",
    "* случайный лес: максимальная F1-мера: 0.565, при n_estimators = 85 (AUC-ROC=0.837), максимальная метрика AUC-ROC = 0.838, при n_estimators = 99(F1-мера = 0.560)\n",
    "\n",
    "изменение порога:\n",
    "* логистическая регрессия: максимальная F1-мера = 0.499, AUC-ROC = 0.758  при пороге = 0.26\n",
    "* решающее дерево: F1-мера = 0.608, AUC-ROC = 0.831 при пороге 0.58 \n",
    "* случайный лес: F1-мера = 0.619, AUC-ROC = 0.837 при пороге 0.28\n",
    "\n",
    "#### Модель случайного леса, при значении гиперпараметра n_estimators=85, указании атрибута class_weight='balanced' и изменении порога, равным 0.28 показала наилучший результат.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируем на случайной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=12345, n_estimators=85, class_weight='balanced') \n",
    "model.fit(features_train, target_train)\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "threshold = 0.28\n",
    "predicted_valid = probabilities_one_valid > threshold\n",
    "valid_f1score = f1_score(target_valid, predicted_valid )\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print('Валидационная выборка:')\n",
    "print('F1-мера:', valid_f1score)\n",
    "print('AUC-ROC:',auc_roc)\n",
    "probabilities_test = model.predict_proba(features_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "predicted_test = probabilities_one_test > threshold\n",
    "test_f1score = f1_score(target_test, predicted_test )\n",
    "auc_roc_test = roc_auc_score(target_test, probabilities_one_test)\n",
    "print('Тестовая выборка:')\n",
    "print('F1-мера:',test_f1score)\n",
    "print('AUC-ROC:',auc_roc_test)\n",
    "\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(target_valid, probabilities_one_valid)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC-кривая')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка на адекватность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем DummyClassifier. Если показатели метрик нашей модели будут выше, чем у фиктивного классификатора, можем признать нашу модель адекватной.\n",
    "Значения strategy переберем циклом, что бы вычислить лучший результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['stratified', 'most_frequent', 'prior', 'uniform']\n",
    "data = []\n",
    "col = ['name', 'f1_score_valid', 'auc_roc_valid', 'f1_score_test', 'auc_roc_test']\n",
    "for name in names:\n",
    "    new_dummy_classifier = DummyClassifier(strategy=name)\n",
    "    new_dummy_classifier.fit(features_train, target_train)\n",
    "\n",
    "    predictions_valid = new_dummy_classifier.predict(features_valid)\n",
    "    valid_accuracy = accuracy_score(target_valid, predictions)\n",
    "    valid_f1score = f1_score(target_valid, predictions_valid)\n",
    "    auc_roc_valid = roc_auc_score(target_valid, predictions_valid)\n",
    "    test_predictions = new_dummy_classifier.predict(features_test)\n",
    "    test_accuracy = accuracy_score(target_test, test_predictions)\n",
    "    test_f1score = f1_score(target_test, test_predictions)\n",
    "    auc_roc_test = roc_auc_score(target_test, test_predictions)\n",
    "    data.append([name, valid_f1score, auc_roc_valid, test_f1score, auc_roc_test])\n",
    "frame = pd.DataFrame(data = data, columns=col)\n",
    "print(frame[frame['f1_score_test']==frame['f1_score_test'].max()]) \n",
    "print(frame[frame['f1_score_valid']==frame['f1_score_valid'].max()].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Показатели у лучшего (при  `strategy='uniform' `) из фиктивных классификаторов гораздо ниже, чем у нашей модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "\n",
    "Главный приз выигрывает модель случайного леса при n_estimators=85,  class_weight='balanced' и изменении порога, равным 0.28.\n",
    "\n",
    "Результаты валидационной выборки:\n",
    "* F1: 0.619\n",
    "* AUC-ROC: 0.837\n",
    "\n",
    "Результаты тестовой выборки:\n",
    "* F1: 0.628 \n",
    "* AUC-ROC: 0.854\n",
    "\n",
    "Модель прошла проверку на адекватность. Лучшие показатели фиктивного классификатора гораздо ниже.\n",
    "\n",
    "значение F1-меры нашей модели равно 0.628 на тестовой выборке - а значит нас ждет успех, ведь мы выполнили требование довести ее до миниму 0.59.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист готовности проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поставьте 'x' в выполненных пунктах. Далее нажмите Shift+Enter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [ ]  Весь код выполняется без ошибок\n",
    "- [ ]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [ ]  Выполнен шаг 1: данные подготовлены\n",
    "- [ ]  Выполнен шаг 2: задача исследована\n",
    "    - [ ]  Исследован баланс классов\n",
    "    - [ ]  Изучены модели без учёта дисбаланса\n",
    "    - [ ]  Написаны выводы по результатам исследования\n",
    "- [ ]  Выполнен шаг 3: учтён дисбаланс\n",
    "    - [ ]  Применено несколько способов борьбы с дисбалансом\n",
    "    - [ ]  Написаны выводы по результатам исследования\n",
    "- [ ]  Выполнен шаг 4: проведено тестирование\n",
    "- [ ]  Удалось достичь *F1*-меры не менее 0.59\n",
    "- [ ]  Исследована метрика *AUC-ROC*"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 2695,
    "start_time": "2022-07-31T09:33:48.051Z"
   },
   {
    "duration": 198,
    "start_time": "2022-07-31T09:33:50.748Z"
   },
   {
    "duration": 12,
    "start_time": "2022-07-31T09:33:50.948Z"
   },
   {
    "duration": 4,
    "start_time": "2022-07-31T09:33:50.963Z"
   },
   {
    "duration": 92,
    "start_time": "2022-07-31T09:33:50.969Z"
   },
   {
    "duration": 7,
    "start_time": "2022-07-31T09:33:51.063Z"
   },
   {
    "duration": 8,
    "start_time": "2022-07-31T09:33:51.072Z"
   },
   {
    "duration": 10,
    "start_time": "2022-07-31T09:33:51.134Z"
   },
   {
    "duration": 19,
    "start_time": "2022-07-31T09:33:51.146Z"
   },
   {
    "duration": 82,
    "start_time": "2022-07-31T09:33:51.168Z"
   },
   {
    "duration": 13,
    "start_time": "2022-07-31T09:33:51.252Z"
   },
   {
    "duration": 2,
    "start_time": "2022-07-31T09:33:51.267Z"
   },
   {
    "duration": 82,
    "start_time": "2022-07-31T09:33:51.271Z"
   },
   {
    "duration": 7,
    "start_time": "2022-07-31T09:33:51.355Z"
   },
   {
    "duration": 87,
    "start_time": "2022-07-31T09:33:51.363Z"
   },
   {
    "duration": 798,
    "start_time": "2022-07-31T09:33:51.453Z"
   },
   {
    "duration": 83209,
    "start_time": "2022-07-31T09:33:52.253Z"
   },
   {
    "duration": 84,
    "start_time": "2022-07-31T09:35:15.464Z"
   },
   {
    "duration": 894,
    "start_time": "2022-07-31T09:35:15.550Z"
   },
   {
    "duration": 85982,
    "start_time": "2022-07-31T09:35:16.452Z"
   },
   {
    "duration": 421,
    "start_time": "2022-07-31T09:36:42.443Z"
   },
   {
    "duration": 395,
    "start_time": "2022-07-31T09:36:42.866Z"
   },
   {
    "duration": 1812,
    "start_time": "2022-07-31T09:36:43.263Z"
   },
   {
    "duration": 1759,
    "start_time": "2022-07-31T09:36:45.077Z"
   },
   {
    "duration": 107,
    "start_time": "2022-07-31T09:36:46.837Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
